Steps,Policy/Entropy,Policy/Extrinsic Value Estimate,Environment/Episode Length,RBSWins,Environment/Cumulative Reward,Policy/Extrinsic Reward,Losses/Value Loss,Losses/Policy Loss,Policy/Learning Rate,Policy/Epsilon,Policy/Beta,Is Training
2000,1.4225147,-7.4272485,99.77777777777777,9.0,0.25,0.25,4.0700107,0.14048101,0.00029937396,0.19979131,0.004989587,1.0
4000,1.4271138,-2.3510656,101.4,19.0,0.2,0.2,0.3477333,0.13486746,0.00029820256,0.19940084,0.004970102,1.0
6000,1.425142,-0.47769552,102.6,29.0,0.3,0.3,0.028335733,0.117243156,0.00029695607,0.19898534,0.0049493685,1.0
8000,1.4315107,-0.11594508,101.7,39.0,0.375,0.375,0.0070564067,0.14206684,0.00029578595,0.1985953,0.004929906,1.0
10000,1.4405091,-0.024462435,100.88888888888889,48.0,0.3333333333333333,0.3333333333333333,0.0060277227,0.13601953,0.00029461473,0.1982049,0.0049104244,1.0
12000,1.4391257,-0.017881349,100.6,58.0,0.35,0.35,0.0058747446,0.12491825,0.00029336326,0.19778775,0.0048896084,1.0
14000,1.4391488,-0.007842218,103.4,68.0,0.475,0.475,0.008447593,0.14471523,0.0002921923,0.19739744,0.0048701316,1.0
16000,1.441853,-0.062016014,103.44444444444444,77.0,0.4166666666666667,0.4166666666666667,0.008391026,0.13771677,0.00029102401,0.197008,0.004850699,1.0
18000,1.4502578,-0.084100336,100.3,87.0,0.425,0.425,0.013833516,0.13272634,0.00028977438,0.19659145,0.0048299134,1.0
20000,1.451878,-0.030028155,102.3,97.0,0.425,0.425,0.011195878,0.13413508,0.0002886026,0.19620085,0.0048104227,1.0
